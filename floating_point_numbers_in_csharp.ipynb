{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20837761",
   "metadata": {},
   "source": [
    "#  Floating-Point Numbers in C#\n",
    "\n",
    "###  *1. Mathematics & Computer Science*\n",
    "- **Fractional Numbers in Math**\n",
    "    - This is a general math term, meaning any number with a fractional part, e.g. 4.56, ½, ⅔, etc. It doesn’t care about how the number is stored.\n",
    "- **Decimal Numbers in Math**\n",
    "    - Number written in base 10\n",
    "        - Any number expressed in the decimal (base-10) system. Example: 7, 42, 1234\n",
    "    - Number with a fractional part (decimal fraction)\n",
    "        - Numbers that use a decimal point to show fractions. Example: 4.56, 0.125, -3.14. Often called decimal fractions.\n",
    "    - Term in positional notation\n",
    "        - Any number expressed using digits 0–9 in positional notation. Example: 345 = 3 × 100 + 4 × 10 + 5 × 1\n",
    "- **Floating-Point Numbers in Computer Science**\n",
    "    - This is a computer science term, meaning a number stored using the floating-point format (float, double in C#). In this format numbers are stored in binary (base 2). This is the main reason that `double` and `float` data types cannot represent exactly some decimal numbers such as `0.1` and `0.2`. Example: double x = 4.56; → this is a floating-point number in C#.\n",
    "- **Decimal Numbers in Computer Science**\n",
    "    - It is a data type different from floating-point types. It’s also a fractional number, but it is stored in a different way (base 10, higher precision for financial calculations). Example: decimal y = 4.56m; → this is a decimal number.\n",
    "\n",
    "### *2. Floating-Point Number Representation in Computer Science*\n",
    "\n",
    "A floating-point number is usually stored in binary scientific notation, similar to how we write decimal scientific notation:\n",
    "\n",
    "$$ (-1)^{\\text{sign}} \\times 1.\\text{mantissa} \\times 2^{\\text{exponent}} $$\n",
    "\n",
    "However, the IEEE 754 standard, which is the industry standard for floating-point arithmetic, defines the formula below, and most modern languages follow it for `float / double` data types:\n",
    "\n",
    "$$ (-1)^{\\text{sign}} \\times 1.\\text{mantissa} \\times 2^{\\text{exponent - bias}} $$\n",
    "\n",
    "**NOTE:** C# follows exact IEEE 754 standard.\n",
    "\n",
    "**Sign bit** (1 bit): Determines if the number is positive (0) or negative (1).\n",
    "\n",
    "**Exponent** (8 bits in single precision, 11 bits in double precision): Encodes the magnitude of the number.\n",
    "\n",
    "**Mantissa** (or fraction/significand, 23 bits in single precision, 52 in double): Encodes the precision digits of the number. The partition after the point.\n",
    "\n",
    "**Bias**: It is a fixed value added to the actual exponent when storing a floating-point number, so that the exponent can be represented as an unsigned number in the binary format.\n",
    "It allows both positive and negative exponents to be stored using only non-negative bits.\n",
    "\n",
    "**Bias values:**\n",
    "\n",
    "32-bit float: bias = 127\n",
    "\n",
    "64-bit double: bias = 1023\n",
    "\n",
    "**Calculating Bias:**\n",
    "\n",
    "    Example (32-bit float in C#)\n",
    "\n",
    "    Exponent field: 8 bits → can store 0..255\n",
    "\n",
    "    Bias = 127\n",
    "\n",
    "    Real exponent = Stored exponent − 127\n",
    "\n",
    "    Stored exponent 129 → real exponent = 129 − 127 = 2\n",
    "\n",
    "    Stored exponent 123 → real exponent = 123 − 127 = -4\n",
    "\n",
    "When reading the stored number, the real exponent is calculated as:\n",
    "$$\n",
    "Real \\; exponent = Stored \\; exponent − Bias\n",
    "$$\n",
    "\n",
    "Graphically a floating-point number in memory is;\n",
    "\n",
    "| **Sign** (1 bit) | **Exponent** (8 bits for float / 11 bits for double) | **Mantissa** (23 bits for float / 52 bits for double) |\n",
    "\n",
    "##### *Different floating-point implememantations;*\n",
    "The differences between programming languages about floating-point standard implementation are mostly occurs in; \n",
    "- Precision and rounding: Rounding behavior might vary slightly depending on compiler or runtime.\n",
    "    - Some languages (like JavaScript) only have 64-bit double for all numbers.\n",
    "- Subnormal numbers / denormals: IEEE 754 allows tiny numbers < min normal (subnormals)\n",
    "    - Handling may differ slightly in speed or hardware implementation.\n",
    "- Special values:\n",
    "    - Infinity, -Infinity, NaN are part of IEEE 754 → supported in all modern languages.\n",
    "\n",
    "### *3. Calculation of Floating-Point Representation*\n",
    "\n",
    "Example 1;\n",
    "\n",
    "    Convert 5.75 into 32-bit float.\n",
    "\n",
    "- Step 1: Convert integer and fraction into binary\n",
    "\n",
    "    - Integer part: `5₁₀ = 101₂`\n",
    "\n",
    "    - Fraction part: `.75 × 2 = 1.5 → 1.5 × 2 = 1.0 → 1`→ Fraction = `.11₂`\n",
    "\n",
    "    - So:\n",
    "\n",
    "        $ 5.75_{10} = 101.11_2 $\n",
    "\n",
    "- Step 2: Normalise (scientific binary form)\n",
    "\n",
    "    - Move binary point so there’s a 1. in front:\n",
    "\n",
    "        $ 101.11_{2} ​= 1.0111_{2}​×2^{2} $\n",
    "    - So:\n",
    "\n",
    "        - Mantissa = `01110...`\n",
    "\n",
    "        - Real Exponent = `2`\n",
    "\n",
    "- Step 3: Encode each part\n",
    "\n",
    "    - **Sign:** positive → `0`\n",
    "\n",
    "    - **Exponent:** Stored exponent = Real exponent + Bias\n",
    "\n",
    "        $ 2 + 127 = 129 = 10000001_{2} $\n",
    "\n",
    "    - **Mantissa:** store only fractional part after `1. → 0111000…` (23 bits)\n",
    "\n",
    "- Step 4: Put it together\n",
    "\n",
    "    - Sign:     `0`\n",
    "\n",
    "    - Exponent: `10000001`\n",
    "\n",
    "    - Mantissa: `01110000000000000000000`\n",
    "\n",
    "- Final binary (32 bits):\n",
    "    - `0 10000001 01110000000000000000000`\n",
    "\n",
    "\n",
    "Example 2;\n",
    "\n",
    "    Convert −0.15625 into 32-bit float.\n",
    "\n",
    "- Step 1: Convert integer and fraction into binary\n",
    "\n",
    "    - Integer part: `0` already binary\n",
    "\n",
    "    - Fraction part: \n",
    "        - `0.15625 × 2 = 0.3125 → 0`\n",
    "        - `0.3125 × 2 = 0.625 → 0`\n",
    "        - `0.625 × 2 = 1.25 → 1`\n",
    "        - `0.25 × 2 = 0.5 → 0`\n",
    "        - `0.5 × 2 = 1.0 → 1`\n",
    "    - So:\n",
    "\n",
    "        $ 0.00101_{2} $\n",
    "\n",
    "- Step 2: Normalise (scientific binary form)\n",
    "\n",
    "    - Move binary point so there’s a 1. in front:\n",
    "\n",
    "        $ 0.00101_{2} = 1.01_{2} × 2^{(-3)} $\n",
    "    - So:\n",
    "\n",
    "        - Mantissa = fractional part after leading 1 → `010`\n",
    "\n",
    "        - Real Exponent = `-3`\n",
    "\n",
    "- Step 3: Encode each part\n",
    "\n",
    "    - **Sign:** negative → `1`\n",
    "\n",
    "    - **Exponent:** Stored exponent = Real exponent + Bias\n",
    "\n",
    "        $ -3 + 127 = 124 = 01111100_{2} $\n",
    "\n",
    "    - **Mantissa:** store only fractional part after `1. → 0100…` (23 bits)\n",
    "\n",
    "- Step 4: Put it together\n",
    "\n",
    "    - Sign:     `1`\n",
    "\n",
    "    - Exponent: `01111100`\n",
    "\n",
    "    - Mantissa: `01000000000000000000000`\n",
    "\n",
    "- Final binary (32 bits):\n",
    "    - `1 01111100 01000000000000000000000`\n",
    "\n",
    "- Bonus: Verification\n",
    "\n",
    "    $ (-1)^{\\text{sign}} \\times 1.\\text{mantissa} \\times 2^{\\text{exponent - bias}} $\n",
    "\n",
    "    $ value = (−1)^1 × 1.01_{2} ​× 2^{−3} $\n",
    "\n",
    "    $ mantissa: 1.01_{2} = 1 + 0.25 $\n",
    "\n",
    "    $ mantissa × exponent:  1.01_{2} × 2^{−3} = 1.25 ÷ 8 = 0.15625$\n",
    "\n",
    "    $ sign × mantissa × exponent: (−1)^1 × 0.15625 = - 0.15625 $\n",
    "\n",
    "### *4. Why Cannot Some Decimal Numbers Be Represented in Floating-Point Format*\n",
    "\n",
    "Example;\n",
    "\n",
    "    Convert 0.1 into 32-bit float.\n",
    "\n",
    "- Step 1: Convert integer and fraction into binary\n",
    "\n",
    "    - Integer part: `0`\n",
    "\n",
    "    - Fraction part: \n",
    "\n",
    "        - `0.1 × 2 = 0.2 → digit = 0`\n",
    "\n",
    "        - `0.2 × 2 = 0.4 → digit = 0`\n",
    "\n",
    "        - `0.4 × 2 = 0.8 → digit = 0`\n",
    "\n",
    "        - `0.8 × 2 = 1.6 → digit = 1, remainder = 0.6`\n",
    "\n",
    "        - `0.6 × 2 = 1.2 → digit = 1, remainder = 0.2`\n",
    "\n",
    "        - `0.2 × 2 = 0.4 → digit = 0`\n",
    "\n",
    "        - `0.4 × 2 = 0.8 → digit = 0`\n",
    "\n",
    "        - `0.8 × 2 = 1.6 → digit = 1, remainder = 0.6`\n",
    "\n",
    "        - `0.6 × 2 = 1.2 → digit = 1, remainder = 0.2`→ Fraction = `.00011001100110011...₂`\n",
    "\n",
    "    - So:\n",
    "\n",
    "        $ 0.1_{10} = 0.00011001100110011..._{2} $\n",
    "\n",
    "- Step 2: Normalise (scientific binary form)\n",
    "\n",
    "    - Move binary point so there’s a 1. in front:\n",
    "\n",
    "        $ 0.00011001100110011..._{2} = 1.1001100..._{2} × 2^{(-4)} $\n",
    "    - So:\n",
    "\n",
    "        - Mantissa = fractional part after leading 1 → `≈ 1.10011001100110011001100` (truncated for 23 bits in float)\n",
    "\n",
    "        - Real Exponent = `-4`\n",
    "\n",
    "- Step 3: Encode each part\n",
    "\n",
    "    - **Sign:** positive → `0`\n",
    "\n",
    "    - **Exponent:** Stored exponent = Real exponent + Bias\n",
    "\n",
    "        $ -4 + 127 = 123 = 01111011_{2} $\n",
    "\n",
    "    - **Mantissa:** store only fractional part after `1. → 10011001100110011001100` (23 bits)\n",
    "\n",
    "- Step 4: Put it together\n",
    "\n",
    "    - Sign:     `0`\n",
    "\n",
    "    - Exponent: `01111011`\n",
    "\n",
    "    - Mantissa: `10011001100110011001101`\n",
    "\n",
    "- Final binary (32 bits / 64 bits):\n",
    "    - `0 01111011 100110011001100110011010` (single-precision)\n",
    "        - Which equals about 0.10000000149011612 in decimal.\n",
    "    - `0 01111011 1001100110011001100110011001100110011001100110011001` (double-precision)\n",
    "        - Which equals about 0.10000000000000000555 in decimal.\n",
    "\n",
    "So;\n",
    "- 0.1 in float ≈ 0.10000000149 (error ≈ 1.5e-9)\n",
    "\n",
    "- 0.1 in double ≈ 0.10000000000000000555 (error ≈ 5.5e-17)\n",
    "\n",
    "- Neither can represent 0.1 exactly, because its binary expansion is infinite repeating.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
